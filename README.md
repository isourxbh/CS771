# major1-2(1)

Project files and example evaluator for a PUF kernel / model-decode challenge.

## Overview

This folder contains example submission code and dataset files used for a PUF (Physical Unclonable Function) modelling task. The repository includes:

- Python evaluator / example scripts that load the datasets, build kernels, train a KernelRidge model, and run a decode routine.
- Public train/test data (`public_x_*.txt`, `public_y_*.txt`, `public_Z_*.txt`) and example model files (`public_mod.txt`).
- A `dummy/` folder with example `submit.py`/`dummy_submit.py` and secret dataset copies used for testing the submission workflow.

## Files (short)

- `major_submit.py` — main script in top-level folder (example runner / submission wrapper).
- `public_mod.txt` — text file with saved model(s) (rows of model vectors). Example loader in the scripts expects this file.
- `public_x_trn.txt`, `public_x_tst.txt` — primary input features (X) for train/test.
- `public_y_trn.txt`, `public_y_tst.txt` — labels (Y) for train/test.
- `public_Z_trn.txt`, `public_Z_tst.txt` — additional input features (Z) for train/test.
- `dummy/submit.py`, `dummy/dummy_submit.py` — example submission templates and a local dummy evaluator/submit helper.

## Dataset format

- `X` files: numeric arrays, often 1-D values per row; example scripts reshape them to `(n, 1)` before combining.
- `Z` files: numeric arrays with additional features; used together with `X` to form combined feature matrices.
- `Y` files: numeric labels / target values for training and evaluation.
- `public_mod.txt`: rows correspond to model vectors used by the decode routine (scripts expect these to be loadable with `np.loadtxt`).

## Requirements

- Python 3.8+ (or newer)
- numpy
- pandas (some example scripts import it)
- scikit-learn

Install with pip:

```bash
python3 -m pip install numpy pandas scikit-learn
```

## How to run (quick)

1. To run the example evaluation / runner (loads data, trains kernel ridge, prints diagnostics):

```bash
python3 major_submit.py
```

2. To run the dummy submission/evaluator in the `dummy/` folder:

```bash
python3 dummy/submit.py
# or
python3 dummy/dummy_submit.py
```

3. Submission packaging: create a ZIP archive that contains a single `submit.py` file. The evaluation harness expects the file `submit.py` with the required function names: `my_kernel(...)` and `my_decode(...)` (do not rename them).

Notes:
- `my_kernel(X1, Z1, X2, Z2)` should compute a Gram (kernel) matrix usable by a kernel ridge regressor.
- `my_decode(w)` should decode a model vector `w` into the requested delay vectors (the example uses rank-1 factorization and mapping to 8 × 32 vectors).

## Development / Debugging tips

- Use `np.loadtxt(...)` to inspect small portions of the .txt files when debugging.
- If you modify `submit.py`, test locally by running the included example evaluator scripts.
- Keep dependency usage limited to `numpy`, `pandas`, and `scikit-learn` (some evaluators disallow other libraries).

## License

Add your preferred license or keep for private use.

---
Created: 2026-02-15 — README autogenerated from repository contents.
